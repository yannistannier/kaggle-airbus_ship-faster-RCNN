{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.encodedPixel = pd.read_csv(\"train_ship_segmentations.csv\", header=0)\n",
    "        self.x_train = pd.read_csv(\"augmentation/train1.csv\", header=-1)[1]\n",
    "        self.x_test = pd.read_csv(\"augmentation/test1.csv\", header=-1)[1]\n",
    "        self.train_batch_count = self.x_train.shape[0] // self.batch_size\n",
    "        self.test_batch_count = self.x_test.shape[0] // 10\n",
    "        self.pp_mean = np.load(\"mean.npy\")\n",
    "        self.shuffle = np.random.permutation(self.x_train.shape[0])\n",
    "    \n",
    "    def normalize(self, batch_images):\n",
    "        return (batch_images - self.pp_mean) / 128.0\n",
    "    \n",
    "    def next_aug_train_batch(self, idx):\n",
    "        link_batch_images = self.x_train[self.shuffle[idx * self.batch_size: (idx + 1) * self.batch_size]]\n",
    "        batch_images = []\n",
    "        batch_mask = []\n",
    "        for x in link_batch_images:\n",
    "            img = cv2.imread('all/train/'+x)\n",
    "            batch_images.append(img)\n",
    "            \n",
    "            rle = self.encodedPixel.query('ImageId==\"'+x+'\"')['EncodedPixels'].tolist()\n",
    "            mask = self.masks_as_image(rle)\n",
    "            batch_mask.append(mask)\n",
    "        \n",
    "        return self.normalize(np.array(batch_images)), np.array(batch_mask)\n",
    "    \n",
    "    def next_test_batch(self, idx):\n",
    "        link_batch_images = self.x_test[self.shuffle[idx * 10: (idx + 1) * 10]]\n",
    "        batch_images = []\n",
    "        batch_mask = []\n",
    "        for x in link_batch_images:\n",
    "            img = cv2.imread('all/train/'+x)\n",
    "            batch_images.append(img)\n",
    "            \n",
    "            rle = self.encodedPixel.query('ImageId==\"'+x+'\"')['EncodedPixels'].tolist()\n",
    "            mask = self.masks_as_image(rle)\n",
    "            batch_mask.append(mask)\n",
    "        \n",
    "        return self.normalize(np.array(batch_images)), np.array(batch_mask)\n",
    "    \n",
    "    \n",
    "    def masks_as_image(self, in_mask_list, all_masks=None):\n",
    "        if all_masks is None:\n",
    "            all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "        #if isinstance(in_mask_list, list):\n",
    "        for mask in in_mask_list:\n",
    "            if isinstance(mask, str):\n",
    "                all_masks += self.rle_decode(mask)\n",
    "        return np.expand_dims(all_masks, -1)\n",
    "\n",
    "    def rle_decode(self, mask_rle, shape=(768, 768)):\n",
    "        s = mask_rle.split()\n",
    "        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "        starts -= 1\n",
    "        ends = starts + lengths\n",
    "        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "        for lo, hi in zip(starts, ends):\n",
    "            img[lo:hi] = 1\n",
    "        return img.reshape(shape).T  # Needed to align to RLE direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augmentation(image, mask):\n",
    "    \"\"\"Returns (maybe) augmented images\n",
    "    (1) Random flip (left <--> right)\n",
    "    (2) Random flip (up <--> down)\n",
    "    (3) Random brightness\n",
    "    (4) Random hue\n",
    "    Args:\n",
    "        image (3-D Tensor): Image tensor of (H, W, C)\n",
    "        mask (3-D Tensor): Mask image tensor of (H, W, 1)\n",
    "    Returns:\n",
    "        image: Maybe augmented image (same shape as input `image`)\n",
    "        mask: Maybe augmented mask (same shape as input `mask`)\n",
    "    \"\"\"\n",
    "    concat_image = tf.concat([image, mask], axis=-1)\n",
    "\n",
    "    maybe_flipped = tf.image.random_flip_left_right(concat_image)\n",
    "    maybe_flipped = tf.image.random_flip_up_down(concat_image)\n",
    "\n",
    "    image = maybe_flipped[:, :, :-1]\n",
    "    mask = maybe_flipped[:, :, -1:]\n",
    "\n",
    "    image = tf.image.random_brightness(image, 0.7)\n",
    "    image = tf.image.random_hue(image, 0.3)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def get_image_mask(queue, augmentation=False):\n",
    "    \"\"\"Returns `image` and `mask`\n",
    "    Input pipeline:\n",
    "        Queue -> CSV -> FileRead -> Decode JPEG\n",
    "    (1) Queue contains a CSV filename\n",
    "    (2) Text Reader opens the CSV\n",
    "        CSV file contains two columns\n",
    "        [\"path/to/image.jpg\", \"path/to/mask.jpg\"]\n",
    "    (3) File Reader opens both files\n",
    "    (4) Decode JPEG to tensors\n",
    "    Notes:\n",
    "        height, width = 640, 960\n",
    "    Returns\n",
    "        image (3-D Tensor): (640, 960, 3)\n",
    "        mask (3-D Tensor): (640, 960, 1)\n",
    "    \"\"\"\n",
    "    text_reader = tf.TextLineReader(skip_header_lines=1)\n",
    "    _, csv_content = text_reader.read(queue)\n",
    "\n",
    "    image_path, mask_path = tf.decode_csv(\n",
    "        csv_content, record_defaults=[[\"\"], [\"\"]])\n",
    "\n",
    "    image_file = tf.read_file(image_path)\n",
    "    mask_file = tf.read_file(mask_path)\n",
    "\n",
    "    image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "    image.set_shape([768, 768, 3])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    mask = tf.image.decode_jpeg(mask_file, channels=1)\n",
    "    mask.set_shape([768, 768, 1])\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask = mask / (tf.reduce_max(mask) + 1e-7)\n",
    "\n",
    "    if augmentation:\n",
    "        image, mask = image_augmentation(image, mask)\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_conv_pool(input_,\n",
    "                   n_filters,\n",
    "                   training,\n",
    "                   flags,\n",
    "                   name,\n",
    "                   pool=True,\n",
    "                   activation=tf.nn.relu):\n",
    "    \"\"\"{Conv -> BN -> RELU}x2 -> {Pool, optional}\n",
    "    Args:\n",
    "        input_ (4-D Tensor): (batch_size, H, W, C)\n",
    "        n_filters (list): number of filters [int, int]\n",
    "        training (1-D Tensor): Boolean Tensor\n",
    "        name (str): name postfix\n",
    "        pool (bool): If True, MaxPool2D\n",
    "        activation: Activaion functions\n",
    "    Returns:\n",
    "        net: output of the Convolution operations\n",
    "        pool (optional): output of the max pooling operations\n",
    "    \"\"\"\n",
    "    net = input_\n",
    "\n",
    "    with tf.variable_scope(\"layer{}\".format(name)):\n",
    "        for i, F in enumerate(n_filters):\n",
    "            net = tf.layers.conv2d(\n",
    "                net,\n",
    "                F, (3, 3),\n",
    "                activation=None,\n",
    "                padding='same',\n",
    "                kernel_regularizer=tf.contrib.layers.l2_regularizer(flags[\"reg\"]),\n",
    "                name=\"conv_{}\".format(i + 1))\n",
    "            net = tf.layers.batch_normalization(\n",
    "                net, training=training, name=\"bn_{}\".format(i + 1))\n",
    "            net = activation(net, name=\"relu{}_{}\".format(name, i + 1))\n",
    "\n",
    "        if pool is False:\n",
    "            return net\n",
    "\n",
    "        pool = tf.layers.max_pooling2d(\n",
    "            net, (2, 2), strides=(2, 2), name=\"pool_{}\".format(name))\n",
    "\n",
    "        return net, pool\n",
    "\n",
    "\n",
    "def upconv_concat(inputA, input_B, n_filter, flags, name):\n",
    "    \"\"\"Upsample `inputA` and concat with `input_B`\n",
    "    Args:\n",
    "        input_A (4-D Tensor): (N, H, W, C)\n",
    "        input_B (4-D Tensor): (N, 2*H, 2*H, C2)\n",
    "        name (str): name of the concat operation\n",
    "    Returns:\n",
    "        output (4-D Tensor): (N, 2*H, 2*W, C + C2)\n",
    "    \"\"\"\n",
    "    up_conv = upconv_2D(inputA, n_filter, flags, name)\n",
    "\n",
    "    return tf.concat(\n",
    "        [up_conv, input_B], axis=-1, name=\"concat_{}\".format(name))\n",
    "\n",
    "\n",
    "def upconv_2D(tensor, n_filter, flags, name):\n",
    "    \"\"\"Up Convolution `tensor` by 2 times\n",
    "    Args:\n",
    "        tensor (4-D Tensor): (N, H, W, C)\n",
    "        n_filter (int): Filter Size\n",
    "        name (str): name of upsampling operations\n",
    "    Returns:\n",
    "        output (4-D Tensor): (N, 2 * H, 2 * W, C)\n",
    "    \"\"\"\n",
    "\n",
    "    return tf.layers.conv2d_transpose(\n",
    "        tensor,\n",
    "        filters=n_filter,\n",
    "        kernel_size=2,\n",
    "        strides=2,\n",
    "        kernel_regularizer=tf.contrib.layers.l2_regularizer(flags[\"reg\"]),\n",
    "        name=\"upsample_{}\".format(name))\n",
    "\n",
    "\n",
    "def make_unet(X, training, flags=None):\n",
    "    \"\"\"Build a U-Net architecture\n",
    "    Args:\n",
    "        X (4-D Tensor): (N, H, W, C)\n",
    "        training (1-D Tensor): Boolean Tensor is required for batchnormalization layers\n",
    "    Returns:\n",
    "        output (4-D Tensor): (N, H, W, C)\n",
    "            Same shape as the `input` tensor\n",
    "    Notes:\n",
    "        U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        https://arxiv.org/abs/1505.04597\n",
    "    \"\"\"\n",
    "    net = X / 127.5 - 1\n",
    "    conv1, pool1 = conv_conv_pool(net, [8, 8], training, flags, name=1)\n",
    "    conv2, pool2 = conv_conv_pool(pool1, [16, 16], training, flags, name=2)\n",
    "    conv3, pool3 = conv_conv_pool(pool2, [32, 32], training, flags, name=3)\n",
    "    conv4, pool4 = conv_conv_pool(pool3, [64, 64], training, flags, name=4)\n",
    "    conv5 = conv_conv_pool(\n",
    "        pool4, [128, 128], training, flags, name=5, pool=False)\n",
    "\n",
    "    up6 = upconv_concat(conv5, conv4, 64, flags, name=6)\n",
    "    conv6 = conv_conv_pool(up6, [64, 64], training, flags, name=6, pool=False)\n",
    "\n",
    "    up7 = upconv_concat(conv6, conv3, 32, flags, name=7)\n",
    "    conv7 = conv_conv_pool(up7, [32, 32], training, flags, name=7, pool=False)\n",
    "\n",
    "    up8 = upconv_concat(conv7, conv2, 16, flags, name=8)\n",
    "    conv8 = conv_conv_pool(up8, [16, 16], training, flags, name=8, pool=False)\n",
    "\n",
    "    up9 = upconv_concat(conv8, conv1, 8, flags, name=9)\n",
    "    conv9 = conv_conv_pool(up9, [8, 8], training, flags, name=9, pool=False)\n",
    "\n",
    "    return tf.layers.conv2d(\n",
    "        conv9,\n",
    "        1, (1, 1),\n",
    "        name='final',\n",
    "        activation=tf.nn.sigmoid,\n",
    "        padding='same')\n",
    "\n",
    "\n",
    "def IOU_(y_pred, y_true):\n",
    "    \"\"\"Returns a (approx) IOU score\n",
    "    intesection = y_pred.flatten() * y_true.flatten()\n",
    "    Then, IOU = 2 * intersection / (y_pred.sum() + y_true.sum() + 1e-7) + 1e-7\n",
    "    Args:\n",
    "        y_pred (4-D array): (N, H, W, 1)\n",
    "        y_true (4-D array): (N, H, W, 1)\n",
    "    Returns:\n",
    "        float: IOU score\n",
    "    \"\"\"\n",
    "    H, W, _ = y_pred.get_shape().as_list()[1:]\n",
    "\n",
    "    pred_flat = tf.reshape(y_pred, [-1, H * W])\n",
    "    true_flat = tf.reshape(y_true, [-1, H * W])\n",
    "\n",
    "    intersection = 2 * tf.reduce_sum(pred_flat * true_flat, axis=1) + 1e-7\n",
    "    denominator = tf.reduce_sum(\n",
    "        pred_flat, axis=1) + tf.reduce_sum(\n",
    "            true_flat, axis=1) + 1e-7\n",
    "\n",
    "    return tf.reduce_mean(intersection / denominator)\n",
    "\n",
    "\n",
    "def make_train_op(y_pred, y_true):\n",
    "    \"\"\"Returns a training operation\n",
    "    Loss function = - IOU(y_pred, y_true)\n",
    "    IOU is\n",
    "        (the area of intersection)\n",
    "        --------------------------\n",
    "        (the area of two boxes)\n",
    "    Args:\n",
    "        y_pred (4-D Tensor): (N, H, W, 1)\n",
    "        y_true (4-D Tensor): (N, H, W, 1)\n",
    "    Returns:\n",
    "        train_op: minimize operation\n",
    "    \"\"\"\n",
    "    loss = -IOU_(y_pred, y_true)\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    optim = tf.train.AdamOptimizer()\n",
    "    return optim.minimize(loss, global_step=global_step)\n",
    "\n",
    "\n",
    "def read_flags():\n",
    "    \"\"\"Returns flags\"\"\"\n",
    "    \n",
    "    return dict({\n",
    "        \"epochs\":100,\n",
    "        \"batch-size\":10,\n",
    "        \"logdir\":\"logdir\",\n",
    "        \"reg\":0.1,\n",
    "        \"ckdir\":\"models\"\n",
    "    })\n",
    "    \n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument(\n",
    "        \"--epochs\", default=1, type=int, help=\"Number of epochs\")\n",
    "\n",
    "    parser.add_argument(\"--batch-size\", default=4, type=int, help=\"Batch size\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--logdir\", default=\"logdir\", help=\"Tensorboard log directory\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--reg\", type=float, default=0.1, help=\"L2 Regularizer Term\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--ckdir\", default=\"models\", help=\"Checkpoint directory\")\n",
    "\n",
    "    flags = parser.parse_args()\n",
    "    return flags\n",
    "\n",
    "\n",
    "def main(flags):\n",
    "    train = pd.read_csv(\"augmentation/train1.csv\")\n",
    "    n_train = train.shape[0]\n",
    "\n",
    "    test = pd.read_csv(\"augmentation/test1.csv\")\n",
    "    n_test = test.shape[0]\n",
    "\n",
    "#     current_time = time.strftime(\"%m/%d/%H/%M/%S\")\n",
    "    train_logdir = os.path.join(flags[\"logdir\"], \"train\")\n",
    "    test_logdir = os.path.join(flags[\"logdir\"], \"test\")\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, shape=[None, 768, 768, 3], name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 768, 768, 1], name=\"y\")\n",
    "    mode = tf.placeholder(tf.bool, name=\"mode\")\n",
    "\n",
    "    pred = make_unet(X, mode, flags)\n",
    "\n",
    "    tf.add_to_collection(\"inputs\", X)\n",
    "    tf.add_to_collection(\"inputs\", mode)\n",
    "    tf.add_to_collection(\"outputs\", pred)\n",
    "\n",
    "    tf.summary.histogram(\"Predicted_Mask\", pred)\n",
    "    tf.summary.image(\"Predicted_Mask\", pred)\n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = make_train_op(pred, y)\n",
    "\n",
    "    IOU_op = IOU_(pred, y)\n",
    "    IOU_op = tf.Print(IOU_op, [IOU_op])\n",
    "    tf.summary.scalar(\"IOU\", IOU_op)\n",
    "\n",
    "#     train_csv = tf.train.string_input_producer(['train.csv'])\n",
    "#     test_csv = tf.train.string_input_producer(['test.csv'])\n",
    "    \n",
    "#     train_image, train_mask = get_image_mask(train_csv)\n",
    "#     test_image, test_mask = get_image_mask(test_csv, augmentation=False)\n",
    "    \n",
    "#     print(train_image)\n",
    "    \n",
    "#     return None\n",
    "    \n",
    "#     X_batch_op, y_batch_op = tf.train.shuffle_batch(\n",
    "#         [train_image, train_mask],\n",
    "#         batch_size=flags[\"batch_size\"],\n",
    "#         capacity=flags[\"batch_size\"] * 5,\n",
    "#         min_after_dequeue=flags[\"batch_size\"] * 2,\n",
    "#         allow_smaller_final_batch=True)\n",
    "\n",
    "#     X_test_op, y_test_op = tf.train.batch(\n",
    "#         [test_image, test_mask],\n",
    "#         batch_size=flags[\"batch_size\"],\n",
    "#         capacity=flags[\"batch_size\"] * 2,\n",
    "#         allow_smaller_final_batch=True)\n",
    "\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    dataset = Dataset(20)\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        train_summary_writer = tf.summary.FileWriter(train_logdir, sess.graph)\n",
    "        test_summary_writer = tf.summary.FileWriter(test_logdir)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        print(\"Start training ......\")\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        if os.path.exists(flags[\"ckdir\"]) and tf.train.checkpoint_exists(flags[\"ckdir\"]):\n",
    "            latest_check_point = tf.train.latest_checkpoint(flags[\"ckdir\"])\n",
    "            print('restoree')\n",
    "            saver.restore(sess, latest_check_point)\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                os.rmdir(flags[\"ckdir\"])\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "            os.mkdir(flags[\"ckdir\"])\n",
    "\n",
    "        try:\n",
    "            global_step = tf.train.get_global_step(sess.graph)\n",
    "\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "            for epoch in range(flags[\"epochs\"]):\n",
    "                print(\"Epoch \", epoch)\n",
    "                \n",
    "                for step in range(dataset.train_batch_count):\n",
    "\n",
    "                    X_batch, y_batch = dataset.next_aug_train_batch(step)\n",
    "\n",
    "                    _, step_iou, step_summary, global_step_value = sess.run(\n",
    "                        [train_op, IOU_op, summary_op, global_step],\n",
    "                        feed_dict={X: X_batch,\n",
    "                                   y: y_batch,\n",
    "                                   mode: True})\n",
    "\n",
    "                    train_summary_writer.add_summary(step_summary,\n",
    "                                                     global_step_value)\n",
    "\n",
    "                total_iou = 0\n",
    "                for step in range(dataset.test_batch_count):\n",
    "                    X_test, y_test = dataset.next_test_batch(step)\n",
    "                    step_iou, step_summary = sess.run(\n",
    "                        [IOU_op, summary_op],\n",
    "                        feed_dict={X: X_test,\n",
    "                                   y: y_test,\n",
    "                                   mode: False})\n",
    "\n",
    "                    total_iou += step_iou * X_test.shape[0]\n",
    "\n",
    "                    test_summary_writer.add_summary(step_summary,\n",
    "                                                    (epoch + 1) * (step + 1))\n",
    "\n",
    "            saver.save(sess, \"{}/model.ckpt\".format(flags[\"ckdir\"]))\n",
    "\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "            saver.save(sess, \"{}/model.ckpt\".format(flags[\"ckdir\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ......\n",
      "restoree\n",
      "INFO:tensorflow:Restoring parameters from models/model.ckpt\n",
      "Epoch  0\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[20,8,768,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients/final/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/final/Conv2D_grad/ShapeN, final/kernel/read, gradients/final/Sigmoid_grad/SigmoidGrad, ^gradients/final/BiasAdd_grad/BiasAddGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'gradients/final/Conv2D_grad/Conv2DBackpropInput', defined at:\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-ccb24ae8f8b2>\", line 3, in <module>\n    main(flags)\n  File \"<ipython-input-14-27867f3641ad>\", line 223, in main\n    train_op = make_train_op(pred, y)\n  File \"<ipython-input-14-27867f3641ad>\", line 159, in make_train_op\n    return optim.minimize(loss, global_step=global_step)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 400, in minimize\n    grad_loss=grad_loss)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 514, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 596, in gradients\n    gate_gradients, aggregation_method, stop_gradients)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 779, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 398, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 779, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py\", line 520, in _Conv2DGrad\n    data_format=data_format),\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1228, in conv2d_backprop_input\n    dilations=dilations, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n...which was originally created as op 'final/Conv2D', defined at:\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 23 identical lines from previous traceback]\n  File \"<ipython-input-15-ccb24ae8f8b2>\", line 3, in <module>\n    main(flags)\n  File \"<ipython-input-14-27867f3641ad>\", line 211, in main\n    pred = make_unet(X, mode, flags)\n  File \"<ipython-input-14-27867f3641ad>\", line 115, in make_unet\n    padding='same')\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 425, in conv2d\n    return layer.apply(inputs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 805, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 362, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 736, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 186, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 956, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[20,8,768,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients/final/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/final/Conv2D_grad/ShapeN, final/kernel/read, gradients/final/Sigmoid_grad/SigmoidGrad, ^gradients/final/BiasAdd_grad/BiasAddGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[20,8,768,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients/final/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/final/Conv2D_grad/ShapeN, final/kernel/read, gradients/final/Sigmoid_grad/SigmoidGrad, ^gradients/final/BiasAdd_grad/BiasAddGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ccb24ae8f8b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/device:GPU:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-27867f3641ad>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(flags)\u001b[0m\n\u001b[1;32m    297\u001b[0m                         feed_dict={X: X_batch,\n\u001b[1;32m    298\u001b[0m                                    \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                                    mode: True})\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     train_summary_writer.add_summary(step_summary,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[20,8,768,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients/final/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/final/Conv2D_grad/ShapeN, final/kernel/read, gradients/final/Sigmoid_grad/SigmoidGrad, ^gradients/final/BiasAdd_grad/BiasAddGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'gradients/final/Conv2D_grad/Conv2DBackpropInput', defined at:\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-ccb24ae8f8b2>\", line 3, in <module>\n    main(flags)\n  File \"<ipython-input-14-27867f3641ad>\", line 223, in main\n    train_op = make_train_op(pred, y)\n  File \"<ipython-input-14-27867f3641ad>\", line 159, in make_train_op\n    return optim.minimize(loss, global_step=global_step)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 400, in minimize\n    grad_loss=grad_loss)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 514, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 596, in gradients\n    gate_gradients, aggregation_method, stop_gradients)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 779, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 398, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 779, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py\", line 520, in _Conv2DGrad\n    data_format=data_format),\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1228, in conv2d_backprop_input\n    dilations=dilations, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n...which was originally created as op 'final/Conv2D', defined at:\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 23 identical lines from previous traceback]\n  File \"<ipython-input-15-ccb24ae8f8b2>\", line 3, in <module>\n    main(flags)\n  File \"<ipython-input-14-27867f3641ad>\", line 211, in main\n    pred = make_unet(X, mode, flags)\n  File \"<ipython-input-14-27867f3641ad>\", line 115, in make_unet\n    padding='same')\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 425, in conv2d\n    return layer.apply(inputs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 805, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 362, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 736, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 186, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 956, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[20,8,768,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients/final/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/final/Conv2D_grad/ShapeN, final/kernel/read, gradients/final/Sigmoid_grad/SigmoidGrad, ^gradients/final/BiasAdd_grad/BiasAddGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    flags = read_flags()\n",
    "    main(flags)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
